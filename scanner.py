#!/usr/bin/env python3
"""
GitHub Action Script - Ultimate Proxy Manager v2.2
- Base64 abonelikleri otomatik Ã§Ã¶zer.
- VMess JSON iÃ§indeki (ps) isimleri ve bayraklarÄ± okur.
- Cloudflare engeli iÃ§in User-Agent eklenmiÅŸtir.
- AkÄ±llÄ± duplicate ve bayrak tespiti iÃ§erir.
"""

import os
import sys
import asyncio
import aiohttp
import re
import json
import base64
import hashlib
import urllib.parse

# UTF-8 ayarÄ± (Emojiler iÃ§in kritik)
sys.stdout.reconfigure(encoding='utf-8')

# --- AYARLAR (GitHub Secrets / Env) ---
CONFIG_URLS = os.getenv("CONFIG_URLS")
YANDEX_TOKEN = os.getenv("YANDEX_TOKEN")
YANDEX_OUTPUT_FILE = os.getenv("YANDEX_OUTPUT_FILE", "/working_configs.txt")
YANDEX_API_BASE = "https://cloud-api.yandex.net/v1/disk"
MAX_CONCURRENT_REQUESTS = int(os.getenv("MAX_CONCURRENT_REQUESTS", "5"))
ENABLE_RENAME = os.getenv("ENABLE_RENAME", "true").lower() == "true"

rename_counter = {}

##################################################
# YARDIMCI ARAÃ‡LAR (DECODE & HASH)
##################################################

def safe_b64_decode(s):
    """Base64 decode - Padding ve URL-safe hatalarÄ±nÄ± giderir."""
    if not s: return ""
    try:
        s = s.strip().replace("-", "+").replace("_", "/")
        padding = len(s) % 4
        if padding:
            s += "=" * (4 - padding)
        return base64.b64decode(s).decode("utf-8", errors="ignore")
    except:
        return ""

def generate_config_hash(link):
    """Config'in benzersiz kimliÄŸini oluÅŸturur (Duplicate kontrolÃ¼)."""
    try:
        # Linkin config kÄ±smÄ±nÄ± al (# sonrasÄ±nÄ± at)
        clean_link = link.split('#')[0]
        
        if clean_link.startswith("vmess://"):
            data_raw = safe_b64_decode(clean_link.replace("vmess://", ""))
            data = json.loads(data_raw)
            # Host, port ve id'yi birleÅŸtirip hashle
            key = f"vmess:{data.get('add')}:{data.get('port')}:{data.get('id')}"
            return hashlib.md5(key.encode()).hexdigest()
        
        elif "://" in clean_link:
            # DiÄŸer protokoller iÃ§in (vless, trojan, ss)
            parsed = urllib.parse.urlparse(clean_link)
            key = f"{parsed.scheme}:{parsed.username}@{parsed.hostname}:{parsed.port}"
            return hashlib.md5(key.encode()).hexdigest()
        
        return hashlib.md5(clean_link.encode()).hexdigest()
    except:
        return hashlib.md5(link.encode()).hexdigest()

##################################################
# Ä°SÄ°MLENDÄ°RME VE BAYRAK ANALÄ°ZÄ°
##################################################

def get_vmess_remark(link):
    """VMess linkinin iÃ§indeki JSON'dan 'ps' (isim) alanÄ±nÄ± Ã§eker."""
    try:
        b64_part = re.sub(r'^vmess://', '', link.split('#')[0], flags=re.IGNORECASE).strip()
        decoded = safe_b64_decode(b64_part)
        if decoded:
            data = json.loads(decoded)
            return str(data.get("ps", "")).strip()
    except:
        pass
    return ""

def rename_config_simple(link):
    """Config'i analiz eder ve Bayrak + Ãœlke Kodu + Protokol olarak yeniden adlandÄ±rÄ±r."""
    if not ENABLE_RENAME:
        return link
    
    try:
        # ProtokolÃ¼ bul (vless, vmess vb.)
        proto_match = re.match(r'^([^:]+)', link)
        proto = proto_match.group(1).lower() if proto_match else "proxy"
        base_link = link.split('#')[0]
        
        # 1. AÅŸama: Ä°sim (remark) bulma
        remark = ""
        if '#' in link:
            # URL sonunda etiket varsa al
            remark = link.split('#', 1)[1]
        
        if not remark and proto == "vmess":
            # Etiket yoksa VMess JSON iÃ§ine bak
            remark = get_vmess_remark(base_link)
        
        # URL Decode (Emoji kodlarÄ±nÄ± gerÃ§ek emojiye Ã§evirir)
        remark = urllib.parse.unquote(remark)

        # 2. AÅŸama: Emoji/Bayrak tespiti
        emoji_pattern = re.compile(r'([\U0001F1E6-\U0001F1FF]{2}|[\U0001F300-\U0001F9FF])')
        emoji_match = emoji_pattern.search(remark)
        
        if not emoji_match:
            # Bayrak yoksa: vmess1, vless2 vb.
            key = proto
            rename_counter[key] = rename_counter.get(key, 0) + 1
            new_name = f"{proto}{rename_counter[key]}"
        else:
            flag = emoji_match.group(1)
            # EÄŸer Ã¼lke bayraÄŸÄ±ysa kodu 3 harfliye Ã§evir (JP -> JAP)
            if len(flag) == 2 and '\U0001F1E6' <= flag[0] <= '\U0001F1FF':
                code_points = [ord(c) - 0x1F1E6 + ord('A') for c in flag]
                c_code = ''.join(chr(c) for c in code_points)
                
                mapping = {
                    "JP": "JAP", "US": "USA", "DE": "GER", "GB": "GBR", "FR": "FRA",
                    "TR": "TUR", "NL": "NLD", "SG": "SGP", "CA": "CAN", "HK": "HKG",
                    "RU": "RUS", "KR": "KOR", "IR": "IRN", "IT": "ITA", "ES": "ESP"
                }
                c_3 = mapping.get(c_code, c_code)
                key = f"{flag}_{c_3}_{proto}"
                rename_counter[key] = rename_counter.get(key, 0) + 1
                new_name = f"{flag}{c_3}-{proto}{rename_counter[key]}"
            else:
                # DiÄŸer emojiler (ğŸ”¥, ğŸŒ)
                key = f"{flag}_{proto}"
                rename_counter[key] = rename_counter.get(key, 0) + 1
                new_name = f"{flag}{proto}{rename_counter[key]}"
        
        return f"{base_link}#{new_name}"
    except:
        return link

##################################################
# VERÄ° Ã‡EKME (HTTP FETCH)
##################################################

async def fetch_configs_from_url(session, url, idx, total):
    """URL'den veriyi Ã§eker, Base64 ise Ã§Ã¶zer ve configleri ayÄ±klar."""
    try:
        print(f"[-] [{idx}/{total}] Ã‡ekiliyor: {url}")
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"}
        
        async with session.get(url.strip(), headers=headers, timeout=30) as resp:
            if resp.status != 200: return []
            
            text = await resp.text()
            
            # --- OTOMATÄ°K BASE64 ABONELÄ°K Ã‡Ã–ZÃœMÃœ ---
            if "://" not in text and len(text.strip()) > 10:
                decoded = safe_b64_decode(text)
                if "://" in decoded:
                    print(f"    [i] Base64 abonelik iÃ§eriÄŸi Ã§Ã¶zÃ¼ldÃ¼.")
                    text = decoded
            
            configs = []
            protos = ['vless://', 'vmess://', 'trojan://', 'ss://', 'ssr://', 'hysteria', 'tuic://']
            
            for line in text.splitlines():
                line = line.strip()
                if not line: continue
                # SatÄ±r bazlÄ± base64 kontrolÃ¼
                if "://" not in line and len(line) > 30:
                    try:
                        d_line = safe_b64_decode(line)
                        if "://" in d_line: line = d_line
                    except: pass
                
                if any(p in line for p in protos):
                    configs.append(line)
            
            return configs
    except Exception as e:
        print(f"    [!] Hata: {url} -> {e}")
        return []

##################################################
# ANA DÃ–NGÃœ VE YÃœKLEME
##################################################

async def yandex_upload(content):
    if not YANDEX_TOKEN: return False
    headers = {"Authorization": f"OAuth {YANDEX_TOKEN}"}
    try:
        async with aiohttp.ClientSession() as sess:
            # YÃ¼kleme linki al
            async with sess.get(f"{YANDEX_API_BASE}/resources/upload", params={"path": YANDEX_OUTPUT_FILE, "overwrite": "true"}, headers=headers) as r:
                if r.status != 200: return False
                url = (await r.json()).get("href")
            # DosyayÄ± gÃ¶nder
            async with sess.put(url, data=content.encode('utf-8')) as r:
                return r.status in [201, 202]
    except: return False

async def main():
    print("ğŸš€ GitHub Action - Proxy Sync v2.2 BaÅŸlatÄ±ldÄ±")
    
    if not CONFIG_URLS:
        print("[!] CONFIG_URLS bulunamadÄ±!"); return

    urls = [u.strip() for u in CONFIG_URLS.split('\n') if u.strip() and not u.startswith('#')]
    all_configs = []

    async with aiohttp.ClientSession() as session:
        tasks = [fetch_configs_from_url(session, url, i+1, len(urls)) for i, url in enumerate(urls)]
        results = await asyncio.gather(*tasks)
        for r in results: all_configs.extend(r)

    if not all_configs:
        print("[!] HiÃ§ config toplanamadÄ±!"); return

    # 1. TekilleÅŸtirme (Hash tabanlÄ±)
    unique_map = {}
    for c in all_configs:
        h = generate_config_hash(c)
        if h not in unique_map: unique_map[h] = c
    
    # 2. Ä°simlendirme
    final_configs = [rename_config_simple(c) for c in unique_map.values()]

    # 3. Yandex Disk'e Kaydet
    content = "\n".join(final_configs)
    if await yandex_upload(content):
        print(f"âœ… BaÅŸarÄ±lÄ±! {len(final_configs)} config Yandex Disk'e yÃ¼klendi.")
    else:
        print("âŒ Yandex Disk yÃ¼klemesi baÅŸarÄ±sÄ±z.")

if __name__ == "__main__":
    asyncio.run(main())
